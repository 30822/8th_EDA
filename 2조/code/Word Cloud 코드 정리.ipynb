{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8105203a",
   "metadata": {},
   "source": [
    "# Size 열 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info['Size'].replace('Varies with device', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info['Size']=df_info['Size'].astype(str)\n",
    "\n",
    "def k_to_m(x):\n",
    "    if 'k' in x:\n",
    "        return float(x.replace('k', ''))/1000\n",
    "    else: return str(x)\n",
    "\n",
    "df_info['Size']=df_info['Size'].apply(k_to_m)\n",
    "\n",
    "df_info['Size']=df_info['Size'].apply(lambda x: x.replace('M',''))\n",
    "\n",
    "df_info['Size']=df_info['Size'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info['Size'].fillna(df_info.groupby('Category')['Size'].transform('mean'),inplace = True)\n",
    "df_info['Size']=np.round(df_info['Size'],decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cac640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "822b28ed",
   "metadata": {},
   "source": [
    "# 전체 리뷰 Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rev=df_review['Translated_Review'].tolist()\n",
    "\n",
    "all_rev=' '.join(all_rev)\n",
    "\n",
    "import re\n",
    "all_text=re.sub(\"[^a-zA-Z]\",\" \", all_rev) #문자를 제외한 나머지 요소 공백으로 바꿈\n",
    "all_text=all_text.lower() #소문자화\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "all_text=nltk.word_tokenize(all_text) #Tokenize\n",
    "all_text_filtered=[word for word in all_text if word not in stopwords.words('english')] #Stopwords 제거\n",
    "\n",
    "import nltk as nlp\n",
    "lemma=nlp.WordNetLemmatizer() #Lemmatization (apps -> app 이런 식으로)\n",
    "all_text_lemma=[lemma.lemmatize(i) for i in all_text_filtered]\n",
    "all_text=[\" \".join(all_text_lemma)]\n",
    "\n",
    "\n",
    "FONT_PATH='/Users/sejeongan/Library/Fonts/Product Sans Regular.ttf'\n",
    "mask=np.array(Image.open('/Users/sejeongan/Downloads/732208.jpg'))\n",
    "\n",
    "plt.subplots(figsize=(10,10))\n",
    "wordcloud=WordCloud(\n",
    "    background_color=\"white\",\n",
    "    width=300,\n",
    "    height=300,\n",
    "    font_path=FONT_PATH,\n",
    "    color_func=ImageColorGenerator(mask),\n",
    "    mask=mask).generate_from_text(\" \".join(all_text))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00d165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe132c40",
   "metadata": {},
   "source": [
    "# Sentiment별 Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87974a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dct = {}\n",
    "for sent in df_review.Sentiment.unique().tolist():\n",
    "\n",
    "    print(sent)\n",
    "    sent_reviews =df_review[df_review['Sentiment'] == sent]\n",
    "    \n",
    "    all_rev=df_review['Translated_Review'].tolist()\n",
    "\n",
    "    all_rev=' '.join(all_rev)\n",
    "\n",
    "    import re\n",
    "    all_text=re.sub(\"[^a-zA-Z]\",\" \", all_rev) \n",
    "    all_text=all_text.lower() \n",
    "\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    all_text=nltk.word_tokenize(all_text)\n",
    "    all_text_filtered=[word for word in all_text if word not in stopwords.words('english')]\n",
    "\n",
    "    import nltk as nlp\n",
    "    lemma=nlp.WordNetLemmatizer()\n",
    "    all_text_lemma=[lemma.lemmatize(i) for i in all_text_filtered] \n",
    "    all_text=[\" \".join(all_text_lemma)]\n",
    "\n",
    "\n",
    "#Word Cloud 생성\n",
    "FONT_PATH='/Users/sejeongan/Library/Fonts/Product Sans Regular.ttf'\n",
    "mask=np.array(Image.open('/Users/sejeongan/Downloads/732208.jpg'))\n",
    "\n",
    "plt.subplots(figsize=(10,10))\n",
    "wordcloud=WordCloud(\n",
    "    background_color=\"white\",\n",
    "    width=300,\n",
    "    height=300,\n",
    "    font_path=FONT_PATH,\n",
    "    color_func=ImageColorGenerator(mask),\n",
    "    mask=mask).generate_from_text(\" \".join(all_text))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00455690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d8948d9",
   "metadata": {},
   "source": [
    "# Category별 Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "review2=df_review.groupby('App').mean()\n",
    "\n",
    "review_apps=review2.index.tolist()\n",
    "app_with_reviews=[]\n",
    "for name in review_apps:\n",
    "    if name in df_info['App'].unique().tolist():\n",
    "        app_with_reviews.append(name)\n",
    "        \n",
    "drop_lst=[]\n",
    "for x in range(0,len(df_info)):\n",
    "    if df_info.App[x] not in app_with_reviews or df_info.App[x] in df_info.App.iloc[:x].values:\n",
    "        drop_lst.append(x)\n",
    "appdata2=df_info.drop(index=drop_lst).reset_index(drop=True)\n",
    "\n",
    "\n",
    "drop_lst2=[]\n",
    "for x in range(0,len(review2)):\n",
    "    if review2.index[x] not in app_with_reviews:\n",
    "        drop_lst2.append(review2.index[x])\n",
    "review3=review2.drop(index=drop_lst2)\n",
    "        \n",
    "data=pd.merge(appdata2,review3, left_on='App', right_on='App')\n",
    "        \n",
    "        \n",
    "df_review_only=df_review.drop(columns=['Sentiment', 'Sentiment_Polarity', 'Sentiment_Subjectivity'])\n",
    "\n",
    "df_review_only2=df_review_only.drop(df_review_only[~df_review_only['App'].isin(app_with_reviews)].index)\n",
    "\n",
    "\n",
    "review_only3=df_review_only2.groupby(['App'], as_index=False).agg({'Translated_Review':' '.join})\n",
    "\n",
    "lst=[]\n",
    "for k in review_only3.App:\n",
    "    for index in range(0,len(data)):\n",
    "        if data.App[index] == k:\n",
    "            lst.append(data.Category[index])\n",
    "s1 = pd.Series(lst)\n",
    "\n",
    "review_only3['Category']=s1\n",
    "review_only3=review_only3[['App', 'Category', 'Translated_Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dct = {}\n",
    "for cat in df_info.Category.unique().tolist():\n",
    "\n",
    "    print(cat)\n",
    "    category_reviews=review_only3[review_only3['Category']==cat]\n",
    "    cat_rev=category_reviews['Translated_Review'].tolist()\n",
    "    cat_rev=' '.join(cat_rev)\n",
    "    for k in ['love','app','great','work','time','good','really','like','thank']:\n",
    "        cat_rev=cat_rev.replace(k,'')\n",
    "\n",
    "    cat_text=re.sub(\"[^a-zA-Z]\",\" \", cat_rev) #문자를 제외한 나머지 요소 공백으로 바꿈\n",
    "    cat_text=cat_text.lower() #소문자화\n",
    "\n",
    "    cat_text=nltk.word_tokenize(cat_text)\n",
    "    cat_text_filtered=[word for word in cat_text if word not in stopwords.words('english')]\n",
    "    \n",
    "    lemma=nltk.WordNetLemmatizer()\n",
    "    cat_text_lemma=[lemma.lemmatize(i) for i in cat_text_filtered]\n",
    "    cat_text=[\" \".join(cat_text_lemma)]\n",
    "    \n",
    "    \n",
    "    FONT_PATH='/Users/sejeongan/Library/Fonts/Product Sans Regular.ttf'\n",
    "    mask=np.array(Image.open('/Users/sejeongan/Downloads/732208.jpg'))\n",
    "    \n",
    "    plt.subplots(figsize=(10,10))\n",
    "    wordcloud=WordCloud(\n",
    "        background_color=\"white\",\n",
    "        width=300,\n",
    "        height=300,\n",
    "        font_path=FONT_PATH,\n",
    "        color_func=ImageColorGenerator(mask),\n",
    "        mask=mask).generate_from_text(\" \".join(cat_text))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ee91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ccb7584",
   "metadata": {},
   "source": [
    "# 1. 카테고리 명 2. 상위권 리뷰 Word Cloud 3. 중위권 리뷰 Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 존재하는 상위권(upper outlier) 앱 추출\n",
    "def out_with_reviews(category):\n",
    "    a_lst=[]\n",
    "    install_lst=[]\n",
    "    app_lst=[]\n",
    "    index_lst=[]\n",
    "    for x in range(0,len(df_info)):\n",
    "        if df_info.Category[x] == category:\n",
    "            app_lst.append(df_info.App[x])\n",
    "            install_lst.append(df_info.Installs[x])\n",
    "    a = np.array(install_lst)\n",
    "    q1,q3= np.percentile(a,[25,75])\n",
    "    IQR = q3 - q1\n",
    "    lower = q1 - (IQR*1.5)\n",
    "    upper = q3 + (IQR*1.5)\n",
    "    \n",
    "    for index,value in enumerate(a):\n",
    "        if (value >= upper):\n",
    "            if app_lst[index] in (app_with_reviews):\n",
    "                a_lst.append(app_lst[index])\n",
    "\n",
    "    for k in range(0,len(review_only3)):\n",
    "        if review_only3.App[k] in a_lst:\n",
    "            index_lst.append(True)\n",
    "        else:\n",
    "            index_lst.append(False)\n",
    "    \n",
    "    return(np.array(index_lst))\n",
    "                \n",
    "    return a_lst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 존재하는 outlier 아닌 앱 추출\n",
    "def out_removed_reviews(category):\n",
    "    a_lst=[]\n",
    "    install_lst=[]\n",
    "    app_lst=[]\n",
    "    index_lst=[]\n",
    "    for x in range(0,len(df_info)):\n",
    "        if df_info.Category[x] == category:\n",
    "            app_lst.append(df_info.App[x])\n",
    "            install_lst.append(df_info.Installs[x])\n",
    "    a = np.array(install_lst)\n",
    "    q1,q3= np.percentile(a,[25,75])\n",
    "    IQR = q3 - q1\n",
    "    lower = q1 - (IQR*1.5)\n",
    "    upper = q3 + (IQR*1.5)\n",
    "    \n",
    "    for index,value in enumerate(a):\n",
    "        if (lower<= value <= upper):\n",
    "            if app_lst[index] in (app_with_reviews):\n",
    "                a_lst.append(app_lst[index])\n",
    "    \n",
    "    for k in range(0,len(review_only3)):\n",
    "        if review_only3.App[k] in a_lst:\n",
    "            index_lst.append(True)\n",
    "        else:\n",
    "            index_lst.append(False)\n",
    "    \n",
    "    return(np.array(index_lst))\n",
    "\n",
    "    return (a_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_PATH='/Users/sejeongan/Library/Fonts/Product Sans Regular.ttf'\n",
    "mask=np.array(Image.open('/Users/sejeongan/Downloads/732208.jpg'))\n",
    "\n",
    "cat_dct = {}\n",
    "for cat in df_info.Category.unique().tolist():\n",
    "\n",
    "    print(cat)\n",
    "    category_reviews=review_only3[out_with_reviews(cat)]\n",
    "    cat_rev=category_reviews['Translated_Review'].tolist()\n",
    "    cat_rev=' '.join(cat_rev)\n",
    "    for k in ['love','app','great','work','time','good','really','like','thank']:\n",
    "        cat_rev=cat_rev.replace(k,'')\n",
    "\n",
    "    cat_text=re.sub(\"[^a-zA-Z]\",\" \", cat_rev) #문자를 제외한 나머지 요소 공백으로 바꿈\n",
    "    cat_text=cat_text.lower() #소문자화\n",
    "\n",
    "    cat_text=nltk.word_tokenize(cat_text)\n",
    "    cat_text_filtered=[word for word in cat_text if word not in stopwords.words('english')]\n",
    "    \n",
    "    lemma=nltk.WordNetLemmatizer()\n",
    "    cat_text_lemma=[lemma.lemmatize(i) for i in cat_text_filtered]\n",
    "    cat_text=[\" \".join(cat_text_lemma)]\n",
    "    \n",
    "    try:\n",
    "        plt.subplots(figsize=(10,10))\n",
    "        wordcloud=WordCloud(\n",
    "            background_color=\"white\",\n",
    "            width=300,\n",
    "            height=300,\n",
    "            font_path=FONT_PATH,\n",
    "            color_func=ImageColorGenerator(mask),\n",
    "            mask=mask).generate_from_text(\" \".join(cat_text))\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    except:\n",
    "        print('결과 없음')\n",
    "        pass\n",
    "    \n",
    "    dog_reviews=review_only3[out_removed_reviews(cat)]\n",
    "    dog_rev=dog_reviews['Translated_Review'].tolist()\n",
    "    dog_rev=' '.join(dog_rev)\n",
    "    for k in ['love','app','great','work','time','good','really','like','thank']:\n",
    "        dog_rev=dog_rev.replace(k,'')\n",
    "\n",
    "    dog_text=re.sub(\"[^a-zA-Z]\",\" \", dog_rev)\n",
    "    dog_text=dog_text.lower()\n",
    "\n",
    "    dog_text=nltk.word_tokenize(dog_text)\n",
    "    dog_text_filtered=[word for word in dog_text if word not in stopwords.words('english')]\n",
    "    \n",
    "    lemma=nltk.WordNetLemmatizer()\n",
    "    dog_text_lemma=[lemma.lemmatize(i) for i in dog_text_filtered]\n",
    "    dog_text=[\" \".join(dog_text_lemma)]\n",
    "    \n",
    "    try:\n",
    "        plt.subplots(figsize=(10,10))\n",
    "        wordcloud=WordCloud(\n",
    "            background_color=\"white\",\n",
    "            width=300,\n",
    "            height=300,\n",
    "            font_path=FONT_PATH,\n",
    "            color_func=ImageColorGenerator(mask),\n",
    "            mask=mask).generate_from_text(\" \".join(dog_text))\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    except:\n",
    "        print('결과 없음')\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
